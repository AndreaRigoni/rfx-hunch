{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hunch models imported\n",
      "reload set for module  Hunch_utils\n",
      "reload set for module  Dummy_g1data\n",
      "reload set for module  Hunch_lsplot\n",
      "reload set for module  Hunch_tSNEplot\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors \n",
    "\n",
    "import ipysh\n",
    "\n",
    "%aimport models.base\n",
    "\n",
    "import Hunch_utils  as Htls\n",
    "import Hunch_lsplot as Hplt\n",
    "import Hunch_tSNEplot as Hsne\n",
    "\n",
    "%aimport Dataset_QSH\n",
    "\n",
    "%aimport models.AEFIT4\n",
    "%aimport models.AEFIT5\n",
    "%aimport models.Compose\n",
    "\n",
    "# ipysh.Bootstrap_support.debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST QSH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QSH rebalanced 15 points size:  47567\n"
     ]
    }
   ],
   "source": [
    "qsh = Dataset_QSH.Dataset_QSH()\n",
    "import os\n",
    "file = ipysh.abs_builddir+'/te_db_r15.npy'\n",
    "if os.path.isfile(file):\n",
    "    qsh.load(file)\n",
    "else:\n",
    "    qsh.load(ipysh.abs_builddir+'/te_db_2.npy')\n",
    "    qsh.rebalance_prel(15)\n",
    "    qsh.save(ipysh.abs_builddir+'/te_db_r15.npy')\n",
    "    \n",
    "qsh.shuffle()\n",
    "qsh.clean_up_poorcurves(5)\n",
    "qsh.dim = None\n",
    "qsh.set_null(np.nan)\n",
    "qsh.set_normal_positive(['prel','te','tbordo','tcentro', 'Ip','NS','VT','F'])\n",
    "qsh.unbias_mean(0.5, 'te')\n",
    "qsh.set_normal_positive(['te'])\n",
    "qsh.clip_values(0.1,0.6)\n",
    "qsh.set_normal_positive(['te'])\n",
    "\n",
    "print(\"QSH rebalanced 15 points size: \", len(qsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0827 15:38:33.070436 140038506567488 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:504: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: id=58, shape=(2, 30), dtype=float32, numpy=\n",
       "  array([[0.02827343, 0.10277789, 0.15121816, 0.20828514, 0.27427357,\n",
       "          0.3485927 , 0.42948723, 0.51404023, 0.59859335, 0.6794879 ,\n",
       "          0.75380695, 0.8197954 , 0.8768625 , 0.9253027 , 0.96593666,\n",
       "          0.4479652 , 0.44344586, 0.45555127, 0.4537953 , 0.5063059 ,\n",
       "          0.5167111 , 0.5173698 , 0.5186978 , 0.52560556, 0.51645434,\n",
       "          0.506659  , 0.46800196, 0.49627608, 0.46119475, 0.40441918],\n",
       "         [0.02827343, 0.10277789, 0.15121816, 0.20828514, 0.27427357,\n",
       "          0.3485927 , 0.42948723, 0.51404023, 0.59859335, 0.6794879 ,\n",
       "          0.75380695, 0.8197954 , 0.8768625 ,        nan, 0.96593666,\n",
       "          0.43686265, 0.44403887, 0.50573033, 0.49210274, 0.5513555 ,\n",
       "          0.5651434 , 0.527565  , 0.5273857 , 0.5077054 , 0.5078784 ,\n",
       "          0.4662639 , 0.4378279 , 0.46724635,        nan, 0.31878376]],\n",
       "        dtype=float32)>, <tf.Tensor: id=59, shape=(2, 6), dtype=float32, numpy=\n",
       "  array([[0.3852216 , 0.2779437 , 0.41836616, 0.6796525 , 0.7426944 ,\n",
       "          0.47269478],\n",
       "         [0.34701556, 0.40717682, 0.9569977 , 0.65200037, 0.8873066 ,\n",
       "          0.59071094]], dtype=float32)>, <tf.Tensor: id=60, shape=(2, 20), dtype=float32, numpy=\n",
       "  array([[ 5.18068206e-03, -2.10580794e-04, -2.90322845e-04,\n",
       "           2.41465145e-03,  2.35645821e-05,  2.05843500e-03,\n",
       "           1.62014924e-03,  4.11712390e-04,  1.65466184e-03,\n",
       "           1.15612173e-03,  8.90054798e-04,  3.30348685e-03,\n",
       "           2.99657229e-03,  1.36369525e-03,  2.42600823e-03,\n",
       "           4.00569465e-04,  1.68996095e-03,  2.44082720e-03,\n",
       "           2.26462915e-04,  1.24659482e-03],\n",
       "         [ 2.70144008e-02, -1.18561089e-03,  2.69618561e-03,\n",
       "           1.72982365e-03, -8.45648290e-04,  1.00630312e-03,\n",
       "           1.73802185e-03,  9.52775590e-04, -1.77119407e-04,\n",
       "           7.18096679e-04,  7.98064470e-03,  2.67556170e-03,\n",
       "           8.46121751e-04,  2.16019130e-03,  2.97028944e-03,\n",
       "           1.84581138e-03,  1.12351554e-04,  1.62017019e-03,\n",
       "           1.10644370e-03,  7.06885476e-04]], dtype=float32)>),\n",
       " (<tf.Tensor: id=61, shape=(2, 30), dtype=float32, numpy=\n",
       "  array([[0.02827343, 0.10277789, 0.15121816, 0.20828514, 0.27427357,\n",
       "          0.3485927 , 0.42948723, 0.51404023, 0.59859335, 0.6794879 ,\n",
       "          0.75380695, 0.8197954 , 0.8768625 , 0.9253027 , 0.96593666,\n",
       "          0.4479652 , 0.44344586, 0.45555127, 0.4537953 , 0.5063059 ,\n",
       "          0.5167111 , 0.5173698 , 0.5186978 , 0.52560556, 0.51645434,\n",
       "          0.506659  , 0.46800196, 0.49627608, 0.46119475, 0.40441918],\n",
       "         [0.02827343, 0.10277789, 0.15121816, 0.20828514, 0.27427357,\n",
       "          0.3485927 , 0.42948723, 0.51404023, 0.59859335, 0.6794879 ,\n",
       "          0.75380695, 0.8197954 , 0.8768625 ,        nan, 0.96593666,\n",
       "          0.43686265, 0.44403887, 0.50573033, 0.49210274, 0.5513555 ,\n",
       "          0.5651434 , 0.527565  , 0.5273857 , 0.5077054 , 0.5078784 ,\n",
       "          0.4662639 , 0.4378279 , 0.46724635,        nan, 0.31878376]],\n",
       "        dtype=float32)>, <tf.Tensor: id=62, shape=(2, 6), dtype=float32, numpy=\n",
       "  array([[0.3852216 , 0.2779437 , 0.41836616, 0.6796525 , 0.7426944 ,\n",
       "          0.47269478],\n",
       "         [0.34701556, 0.40717682, 0.9569977 , 0.65200037, 0.8873066 ,\n",
       "          0.59071094]], dtype=float32)>, <tf.Tensor: id=63, shape=(2, 20), dtype=float32, numpy=\n",
       "  array([[ 5.18068206e-03, -2.10580794e-04, -2.90322845e-04,\n",
       "           2.41465145e-03,  2.35645821e-05,  2.05843500e-03,\n",
       "           1.62014924e-03,  4.11712390e-04,  1.65466184e-03,\n",
       "           1.15612173e-03,  8.90054798e-04,  3.30348685e-03,\n",
       "           2.99657229e-03,  1.36369525e-03,  2.42600823e-03,\n",
       "           4.00569465e-04,  1.68996095e-03,  2.44082720e-03,\n",
       "           2.26462915e-04,  1.24659482e-03],\n",
       "         [ 2.70144008e-02, -1.18561089e-03,  2.69618561e-03,\n",
       "           1.72982365e-03, -8.45648290e-04,  1.00630312e-03,\n",
       "           1.73802185e-03,  9.52775590e-04, -1.77119407e-04,\n",
       "           7.18096679e-04,  7.98064470e-03,  2.67556170e-03,\n",
       "           8.46121751e-04,  2.16019130e-03,  2.97028944e-03,\n",
       "           1.84581138e-03,  1.12351554e-04,  1.62017019e-03,\n",
       "           1.10644370e-03,  7.06885476e-04]], dtype=float32)>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bt_min, Bt_max = np.nanmin(qsh['Bt']), np.nanmax(qsh['Bt'])\n",
    "def _map(xy,p,Bt):\n",
    "    # Bt = (Bt-Bt_min)/(Bt_max-Bt_min)\n",
    "    return (xy,p,Bt),(xy,p,Bt)\n",
    "# ds = qsh.tf_tuple_compose(['prel','te','tbordo~tcentro~Ip~NS~VT~F','absBt_rm~argBt_rm']).map(lambda x,y,t,s: (_map(x,y,t,s)) )\n",
    "# ds = qsh.tf_tuple_compose(['prel~te:15','tbordo~tcentro~Ip~NS~VT~F','absBt_rm~argBt_rm']).map(lambda x,y,z: ((x,y,z),(x,y,z)))\n",
    "ds = qsh.tf_tuple_compose(['prel~te:15','tbordo~tcentro~Ip~NS~VT~F','Bt']).map(lambda x,y,z: _map(x,y,z) )\n",
    "[x for x in ds.shuffle(100).batch(2).take(1)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEFIT5 ready:\n",
      "AEFIT5 ready:\n",
      "AEFIT5 ready:\n",
      "AEFIT5 ready:\n",
      "[(None, 30), (None, 6), (None, 20)]\n"
     ]
    }
   ],
   "source": [
    "m1 = models.AEFIT5.AEFIT5(latent_dim=10, feature_dim=30,  dprate=0., scale=2, geometry=[20,20,10,10], beta=0.) #beta=0.001)\n",
    "m1.load('step10_qsh_fit5_l10')\n",
    "m2 = models.AEFIT5.AEFIT5(latent_dim=6, feature_dim=6,  dprate=0., scale=1, beta=0., name='temp', geometry=[]) # parameters\n",
    "m3 = models.AEFIT5.AEFIT5(latent_dim=20, feature_dim=20,  dprate=0., scale=1, beta=0., name='spectrum', geometry=[]) # spectrum\n",
    "# m3.compile( loss=tf.keras.losses.mean_squared_error )\n",
    "# m2i = tf.keras.Sequential([ tf.keras.layers.InputLayer(input_shape=(6,)) ])\n",
    "# m2i.compile( optimizer=tf.keras.optimizers.Adam(1e-3), loss=tf.keras.losses.mean_absolute_error )\n",
    "hm_feature_dim = m1.latent_dim + m2.latent_dim + m3.latent_dim\n",
    "hm = models.AEFIT5.AEFIT5(latent_dim=2, feature_dim=hm_feature_dim, beta=0., scale=1, name='hidden', geometry=[20,20,20])\n",
    "h = models.Compose.Compose().set_model(hm).compose([m1,m2,m3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.trainable = False\n",
    "m2.trainable = False\n",
    "m3.trainable = False\n",
    "hm.trainable = True\n",
    "h.loss_weights = [0.6,0.2,0.2]\n",
    "h.compile( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d000adbf08ab410993f4c2ea477865eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0bae0be7474c7f80af986ae79a58bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3604639578664f76b9ffae450b78773d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c3442785ab435f9ae8dab544d588c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING: you are tryig to set a loss where losses should come directly from compose models\n",
      "475/475 [==============================] - 22s 47ms/step - loss: 22.5625 - output_1_loss: 18.6595 - output_2_loss: 3.8308 - output_3_loss: 0.6638\n",
      "Epoch 2/30\n",
      "415/475 [=========================>....] - ETA: 2s - loss: 22.3456 - output_1_loss: 18.5670 - output_2_loss: 3.5462 - output_3_loss: 0.2530"
     ]
    }
   ],
   "source": [
    "# hm.beta = 1.\n",
    "# h.compile()\n",
    "models.base.train_thread(h, ds, epoch=30, batch=100, learning_rate=1e-3, callbacks=[]).control_panel()\n",
    "# h.fit(ds.batch(100), epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm2 = models.AEFIT5.AEFIT5(latent_dim=2, feature_dim=h.latent_dim, beta=0., scale=1, name='hm2', geometry=[10])\n",
    "h2  = models.Compose.Compose().set_model(hm2).compose([h])\n",
    "hm2.trainable = True\n",
    "h.trainable = False\n",
    "h2.compile( loss=hm2.loss )\n",
    "\n",
    "models.base.train_thread(h2, ds, epoch=3, batch=100, learning_rate=1e-3, callbacks=[]).control_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Hplt.LSPlotBokeh()\n",
    "p.set_model(h)\n",
    "p.set_data(qsh, feed_data=ds, counts=1000)\n",
    "p.plot(notebook_url='http://172.17.0.2:8888')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [ v.name for v in h2.trainable_variables ]\n",
    "def plot(xy):\n",
    "    plt.figure('data')\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(0.,1.)\n",
    "    x,y = tf.split(xy[0], num_or_size_splits=2)\n",
    "    plt.plot(x,y,'.')\n",
    "d = [x for x in ds.shuffle(1000).batch(1).take(100)][0]\n",
    "d0 = d[0][0]\n",
    "y0 = h(d[0], training=False)\n",
    "y0 = tf.sigmoid(y0[0])\n",
    "plot(d0)\n",
    "plot(y0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbordo tcentro Ip NS VT F\n",
    "xy,_ =  [x for x in ds.batch(1).take(1)][0]\n",
    "par = xy[2]\n",
    "\n",
    "l,_ = h.encode(xy, training=False)\n",
    "XY  = h.decode(l, training=False, apply_sigmoid=True) \n",
    "PAR = XY[2]\n",
    "\n",
    "print( list(zip(par, PAR)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure('test_curve',figsize=(18, 6))\n",
    "plt.clf()\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)    \n",
    "# ax1.set_xlim(-2.,2.)\n",
    "ax2.set_ylim(0.,1.)\n",
    "\n",
    "# sx = []\n",
    "# sy = []\n",
    "# for xy in ds.batch(1).take(1000):\n",
    "#     xy,_ = xy\n",
    "#     x,y = tf.split(xy[0],2, axis=1)\n",
    "#     me,_  = h.encode(xy, training=False)\n",
    "#     gpt = me[0].numpy()\n",
    "#     #ax1.scatter(gpt[0],gpt[1])\n",
    "#     sx.append(gpt[0])\n",
    "#     sy.append(gpt[1])\n",
    "\n",
    "# ax1.scatter(sx,sy)\n",
    "    \n",
    "for xy in ds.shuffle(100).batch(1).take(1):    \n",
    "    xy,_ = xy\n",
    "    x,y = tf.split(xy[0],2, axis=1)\n",
    "    ax2.scatter(x,y,s=80)\n",
    "    me,_  = h.encode(xy, training=False)\n",
    "    gpt = me[0].numpy()\n",
    "    ax1.scatter(gpt[0],gpt[1])\n",
    "    \n",
    "    XY = h.decode(me, training=False)[0]\n",
    "    XY = tf.sigmoid(XY)\n",
    "    X,Y = tf.split(XY[0], num_or_size_splits=2)\n",
    "    X,Y = (X.numpy(), Y.numpy())\n",
    "    ax2.scatter(X,Y,s=40)\n",
    "\n",
    "print(qsh_pos)    \n",
    "qsh_pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy,_ = [x for x in ds.batch(2).take(1)][0]\n",
    "me,va = h.encode(xy)\n",
    "XY = h.decode(me, apply_sigmoid=True)\n",
    "XY[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
